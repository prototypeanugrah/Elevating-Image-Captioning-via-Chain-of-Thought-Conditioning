{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "stopwords.extend(['from', 'city', 'tall', 'building', 'image', 'capture', 'street', 'white', 'car', 'black', 'sky', 'table', 'moped', 'red', 'two', 'house', 'water', 'boat', 'stand', 'scence', 'heart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv('results/post_survey.csv')\n",
    "caption_a = main_data['caption_A'].tolist()\n",
    "caption_b = main_data['caption_B'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "caption_a = [simple_preprocess(str(doc), deacc=True) for doc in caption_a]\n",
    "caption_b = [simple_preprocess(str(doc), deacc=True) for doc in caption_b]\n",
    "\n",
    "# Remove stopwords\n",
    "caption_a = [[word for word in simple_preprocess(str(doc)) if word not in stopwords] for doc in caption_a]\n",
    "caption_b = [[word for word in simple_preprocess(str(doc)) if word not in stopwords] for doc in caption_b]\n",
    "\n",
    "# Lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "caption_a = [[lemmatizer.lemmatize(word) for word in simple_preprocess(str(doc))] for doc in caption_a]\n",
    "caption_b = [[lemmatizer.lemmatize(word) for word in simple_preprocess(str(doc))] for doc in caption_b]\n",
    "\n",
    "# Remove specific words that are not useful\n",
    "extend_list = ['capture', 'scene', 'urban']\n",
    "caption_a = [[word for word in simple_preprocess(str(doc)) if word not in extend_list] for doc in caption_a]\n",
    "caption_b = [[word for word in simple_preprocess(str(doc)) if word not in extend_list] for doc in caption_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 most common words in the captions - caption_a and caption_b\n",
    "def get_top_words(caption):\n",
    "    words = [word for doc in caption for word in doc]\n",
    "    word_freq = Counter(words)\n",
    "    top_words = word_freq.most_common(10)\n",
    "    return top_words\n",
    "\n",
    "top_words_a = get_top_words(caption_a)\n",
    "top_words_b = get_top_words(caption_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in caption A: [('serene', 24), ('bustling', 23), ('vibrant', 17), ('adorned', 11), ('glow', 11), ('cozy', 10), ('moment', 10), ('nestled', 10), ('amidst', 9), ('bathed', 9)]\n",
      "Top 10 words in caption B: [('serene', 27), ('vibrant', 21), ('bustling', 20), ('dominating', 19), ('large', 16), ('color', 13), ('man', 11), ('standing', 10), ('building', 10), ('woman', 10)]\n"
     ]
    }
   ],
   "source": [
    "print('Top 10 words in caption A:', top_words_a)\n",
    "print('Top 10 words in caption B:', top_words_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cozy', 'kitchen', 'refrigerator', 'standing', 'amidst', 'backdrop', 'wooden', 'cabinet', 'shelf', 'adorned', 'various', 'item', 'touch', 'personal', 'flair']]\n",
      "[['cozy', 'kitchen', 'dominating', 'center', 'frame', 'large', 'refrigerator', 'standing', 'sleek', 'right', 'wooden', 'cabinet', 'glass', 'door', 'showcase', 'array', 'dish', 'glassware']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "caption_a = list(sent_to_words(caption_a))\n",
    "caption_b = list(sent_to_words(caption_b))\n",
    "\n",
    "print(caption_a[:1])\n",
    "print(caption_b[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]]\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "caption_a_id2word = corpora.Dictionary(caption_a)\n",
    "caption_b_id2word = corpora.Dictionary(caption_b)\n",
    "\n",
    "# Create Corpus\n",
    "caption_a_texts = caption_a\n",
    "caption_b_texts = caption_b\n",
    "\n",
    "# Term Document Frequency\n",
    "caption_a_corpus = [caption_a_id2word.doc2bow(text) for text in caption_a_texts]\n",
    "caption_b_corpus = [caption_b_id2word.doc2bow(text) for text in caption_b_texts]\n",
    "\n",
    "# View\n",
    "print(caption_a_corpus[:1])\n",
    "print(caption_b_corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "caption_a_lda_model = LdaModel(corpus=caption_a_corpus,\n",
    "                               id2word=caption_a_id2word,\n",
    "                               num_topics=5,\n",
    "                               random_state=100,\n",
    "                               update_every=1,\n",
    "                               chunksize=100,\n",
    "                               passes=10,\n",
    "                               alpha='auto',\n",
    "                               per_word_topics=True)\n",
    "\n",
    "caption_b_lda_model = LdaModel(corpus=caption_b_corpus,\n",
    "                                id2word=caption_b_id2word,\n",
    "                                num_topics=5,\n",
    "                                random_state=100,\n",
    "                                update_every=1,\n",
    "                                chunksize=100,\n",
    "                                passes=10,\n",
    "                                alpha='auto',\n",
    "                                per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.019*\"bustling\" + 0.016*\"serene\" + 0.013*\"vibrant\" + 0.013*\"color\" + '\n",
      "  '0.013*\"boat\" + 0.013*\"market\" + 0.010*\"harbor\" + 0.010*\"mix\" + '\n",
      "  '0.010*\"silver\" + 0.010*\"side\"'),\n",
      " (1,\n",
      "  '0.015*\"serene\" + 0.015*\"glow\" + 0.012*\"bustling\" + 0.010*\"townhouses\" + '\n",
      "  '0.010*\"row\" + 0.010*\"setting\" + 0.010*\"warm\" + 0.010*\"nestled\" + '\n",
      "  '0.010*\"bathed\" + 0.010*\"pink\"'),\n",
      " (2,\n",
      "  '0.013*\"moment\" + 0.013*\"modern\" + 0.011*\"parked\" + 0.011*\"serene\" + '\n",
      "  '0.011*\"painted\" + 0.011*\"blend\" + 0.011*\"architecture\" + 0.011*\"bustling\" + '\n",
      "  '0.009*\"window\" + 0.009*\"large\"'),\n",
      " (3,\n",
      "  '0.012*\"serene\" + 0.010*\"adorned\" + 0.010*\"man\" + 0.010*\"room\" + '\n",
      "  '0.008*\"bustling\" + 0.008*\"home\" + 0.008*\"bathed\" + 0.008*\"greenery\" + '\n",
      "  '0.008*\"amidst\" + 0.008*\"vibrant\"'),\n",
      " (4,\n",
      "  '0.012*\"vibrant\" + 0.012*\"bustling\" + 0.011*\"coffee\" + 0.009*\"stand\" + '\n",
      "  '0.009*\"amidst\" + 0.009*\"lush\" + 0.009*\"soft\" + 0.009*\"cozy\" + '\n",
      "  '0.009*\"serene\" + 0.009*\"lamp\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(caption_a_lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.015*\"serene\" + 0.013*\"boat\" + 0.013*\"cozy\" + 0.013*\"wooden\" + '\n",
      "  '0.010*\"across\" + 0.010*\"kitchen\" + 0.010*\"array\" + 0.007*\"vibrant\" + '\n",
      "  '0.007*\"tree\" + 0.007*\"color\"'),\n",
      " (1,\n",
      "  '0.019*\"serene\" + 0.017*\"large\" + 0.013*\"dominating\" + 0.012*\"color\" + '\n",
      "  '0.012*\"boat\" + 0.011*\"bustling\" + 0.010*\"vibrant\" + 0.010*\"window\" + '\n",
      "  '0.009*\"facade\" + 0.008*\"frame\"'),\n",
      " (2,\n",
      "  '0.017*\"serene\" + 0.013*\"inviting\" + 0.013*\"lush\" + 0.013*\"amidst\" + '\n",
      "  '0.013*\"nestled\" + 0.012*\"stand\" + 0.012*\"backdrop\" + 0.010*\"seated\" + '\n",
      "  '0.010*\"highway\" + 0.010*\"desk\"'),\n",
      " (3,\n",
      "  '0.020*\"vibrant\" + 0.015*\"standing\" + 0.015*\"dominating\" + 0.015*\"bustling\" '\n",
      "  '+ 0.013*\"man\" + 0.012*\"architecture\" + 0.011*\"building\" + 0.010*\"feature\" + '\n",
      "  '0.010*\"blue\" + 0.010*\"large\"'),\n",
      " (4,\n",
      "  '0.013*\"serene\" + 0.010*\"bustling\" + 0.010*\"range\" + 0.010*\"building\" + '\n",
      "  '0.010*\"stone\" + 0.009*\"dominating\" + 0.007*\"reflecting\" + 0.007*\"steel\" + '\n",
      "  '0.007*\"kitchen\" + 0.007*\"light\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(caption_b_lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in caption A LDA: [[('bustling', 0.01917184)], [('serene', 0.014575318)], [('moment', 0.01328289)], [('serene', 0.012236543)], [('vibrant', 0.011524313)]]\n",
      "Top 10 words in caption B LDA: [[('serene', 0.015270692)], [('serene', 0.019419868)], [('serene', 0.017491214)], [('vibrant', 0.020404482)], [('serene', 0.012934917)]]\n"
     ]
    }
   ],
   "source": [
    "# Print the top 10 words in each topic\n",
    "def get_top_words_lda(lda_model):\n",
    "    top_words = []\n",
    "    for i in range(5):\n",
    "        top_words.append(lda_model.show_topic(i, 1))\n",
    "    return top_words\n",
    "\n",
    "top_words_a_lda = get_top_words_lda(caption_a_lda_model)\n",
    "top_words_b_lda = get_top_words_lda(caption_b_lda_model)\n",
    "\n",
    "print('Top words in caption A LDA:', top_words_a_lda)\n",
    "print('Top words in caption B LDA:', top_words_b_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.678012996944656\n",
      "\n",
      "Perplexity:  -6.583239955791799\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', caption_a_lda_model.log_perplexity(caption_a_corpus))  # a measure of how good the model is. lower the better.\n",
    "print('\\nPerplexity: ', caption_b_lda_model.log_perplexity(caption_b_corpus))  # a measure of how good the model is. lower the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score for caption A:  0.38956967028974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score for caption B:  0.4131604442484684\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "caption_a_coherence_model_lda = CoherenceModel(model=caption_a_lda_model, texts=caption_a, dictionary=caption_a_id2word, coherence='c_v')\n",
    "caption_a_coherence_lda = caption_a_coherence_model_lda.get_coherence()\n",
    "print('Coherence Score for caption A: ', caption_a_coherence_lda)\n",
    "\n",
    "caption_b_coherence_model_lda = CoherenceModel(model=caption_b_lda_model, texts=caption_b, dictionary=caption_b_id2word, coherence='c_v')\n",
    "caption_b_coherence_lda = caption_b_coherence_model_lda.get_coherence()\n",
    "print('Coherence Score for caption B: ', caption_b_coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "import pyLDAvis.gensim\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import os\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('results/ldavis_prepared_'+str(5))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(caption_a_lda_model, caption_a_corpus, caption_a_id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "    \n",
    "pyLDAvis.save_html(LDAvis_prepared, 'results/ldavis_prepared_'+ str(5) +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
